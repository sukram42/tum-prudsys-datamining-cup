{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Temp._Test.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EkjlTkz99c_Y","colab_type":"text"},"source":["# Simple preprocessing\n","\n","\n","Hello People! \n","\n","Welcome to the first Notebook. \n","\n","Like we described in our presentation. This is notebook is used for the creation of easy features. \n","\n","__What is an easy feature?__\n","\n","You can think of it like a column in one of the data files. At the beginning\n","we have the three input files (items, info, orders). In the end we will export 2 files: \n","- ```dynamic_features.pkl```-> All time dependent data such as date features (e.g day_of_month)\n","- ```static_features.pkl```-> All static features such as itemID and so on\n","\n","After this notebook we **only** work with ```dynamic_features.pkl``` and ```static_features.pkl```.\n","\n","_Why the fuck ```*.pkl```?!_ \n","\n","pkl in this case stands for 'pickle' and allows us to very space efficiently safe the data in bytes. When loading the data we don't have the problem with delimiters like we would have with csv. But most important: Later we need to save models and so on with pickle. So we already start here using it to have some consistency in these unconsistent times :D\n","\n","__How do we handle our test set ?__\n","As we already tried out in team 1, it is crucial to think about the complexity of test features beforehand. Therefore, we now prepare the test set from right the beginning. \n","\n","This means that we now already created rows for the testset. This means the aforementioned files then consist out of **all** the data (test + validation + train). _But why?!_ In the first two notebooks we have function (later more about those) to mutate our data. These mutation then directly can be done for test and train set, using the same functions. This finally leads to correct function. Furthermore, everyone who is adding a new feature now already needs to think about, how it may be applied to the train set (in which we have not all information)\n","\n","How the creation of testset features works, will be elaborated later. \n","\n","__What is the structure of this notebook?__\n","\n","1. **Setting up Colab**\n","1. **Notes and Ideas**\n","1. **Setting up Notebook**\n","1. **Create Dynamic_Features Dataframe** \n","1. **Deviation of Promotions and Creation of Test Set**\n","1. **Defining Feature Functions**\n","1. **Applying Features**\n","1. **Testset Mappings**\n","1. **Saving data**\n","\n","__TL;DR__\n","- Input = data.csv/ items.csv / orders.csv\n","- Output = dynamic_features.csv / static_features.csv\n","- Notebook for easy features (new Columns in source data)\n","- Test set is simulated and created already here.\n"]},{"cell_type":"markdown","metadata":{"id":"P94sbukY70Ka","colab_type":"text"},"source":["# 1. Setting up Colab\n","\n","Here we set up colab. U knooow it :D \n","\n","In case u don't use colab, please specify the variable ```use_colab``` to false. In case u don't use it its unavoidable to make sure that noone changed something online while u change it offline. The results of this would be worse than a division by zero.  "]},{"cell_type":"code","metadata":{"id":"9OwEnQ9q90xk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397898505,"user_tz":-120,"elapsed":1143,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["use_colab: bool = True"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-aKdIiCP-DAh","colab_type":"text"},"source":["In case u accidentall run the following code twice u will get following weird and confusing error:\n","\n","```\n","OSError: [Errno 107] Transport endpoint is not connected\n","```\n","\n","In this case just restart the runtime above. \n"]},{"cell_type":"code","metadata":{"id":"NW-V0LwRFBrz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1592397900557,"user_tz":-120,"elapsed":3179,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"28649aac-0e40-42b7-aa21-aab1e15c75d0"},"source":["if use_colab:\n","  import os\n","  from google.colab import drive \n","  drive.mount(\"/content/gdrive\", force_remount=True)\n","  # Change directory for nicer imports\n","  %cd \"/content/gdrive/My Drive/Data_Mining_Cup/05 Code/\"\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Data_Mining_Cup/05 Code\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o0G7khZfI-7B","colab_type":"text"},"source":["# 2. Nodes and Ideas"]},{"cell_type":"markdown","metadata":{"id":"FhkpJPxiJBhP","colab_type":"text"},"source":["## Ideas for new Features\n","Please specify assignment in bold and brackets behind. If nobody is assigned put the \"To Be Assigned (TBA)\" Flague.\n","\n","- Boolean two days after promotion (Nic)\n","- avg sold on not-promoted day **(TBA)**\n","- avg sold on promoted day **(TBA)**\n","- how rare are solds **(TBA)**\n","- Days since last sale **(TBA)**\n","- Sum of solds 14 days after -> Can be used for the direct prediction of sum of values **(TBA)**\n"]},{"cell_type":"markdown","metadata":{"id":"xuI6qXPWJehT","colab_type":"text"},"source":["## Notes\n","\n","Currently no notes :( "]},{"cell_type":"markdown","metadata":{"id":"qg-T8Iok8z_X","colab_type":"text"},"source":["# 3. Setting up Notebook\n","\n","Here we setup some parameters for the notebook to work in the expected ways."]},{"cell_type":"markdown","metadata":{"id":"8LRU5vmI9eCt","colab_type":"text"},"source":["If we want to **use the final test phase** for the later submission, we need to specify the following parameter **```make_final_submission``` to true.** Otherwise the selfmade test set will be used."]},{"cell_type":"code","metadata":{"id":"LDWM8LmV_KkE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397900558,"user_tz":-120,"elapsed":3161,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["make_final_submission: bool = False"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JVVjiq__R7I","colab_type":"text"},"source":["In case we don't want to make a final submission, we now have to specify the test_set. In case you change it, please leave a comment on why and what the new one is. If the end is defined as None we use all the data from start_period (inclusive) till the end of dataset. \n","\n","In case make_final_submission is True we do not use those parameters."]},{"cell_type":"code","metadata":{"id":"KvKp58Ug_QwD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397900559,"user_tz":-120,"elapsed":3150,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# This will set the start of test period to 2 weeks before end of data\n","test_period_start: str=\"2018-06-02\"\n","# Use till the end\n","test_period_end: str=\"2018-06-15\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThuLP_PksLxg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397900560,"user_tz":-120,"elapsed":3139,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# These datapoints are for the final submision\n","final_submission_start: str=\"2018-06-30\"\n","final_submission_end: str=\"2018-07-13\"  # shouldn't it be 07-13 if inclusive? "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P01Jd3yw9GXT","colab_type":"text"},"source":["#### Imports\n","\n","Here you can add imports u need. Please use alphabetical order to not import new stuff twice."]},{"cell_type":"code","metadata":{"id":"vWcDzESD8HZ6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397900561,"user_tz":-120,"elapsed":3122,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["from datetime import datetime\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from typing import List, Callable\n","\n","%matplotlib inline\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qynB18E7ASmI","colab_type":"text"},"source":["### Data Imports\n","\n","Now we import the source data. In case we use our test set, we delete the test set values to simulate later submission."]},{"cell_type":"code","metadata":{"id":"s1sqbn-Oq1QT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397900562,"user_tz":-120,"elapsed":3113,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# In tables 'infos' and 'items' itemID is used as index\n","info = pd.read_csv('/content/gdrive/My Drive/Data_Mining_Cup/02 Data/DMC20_Data/infos.csv', delimiter='|', index_col=\"itemID\")\n","items = pd.read_csv('/content/gdrive/My Drive/Data_Mining_Cup/02 Data/DMC20_Data/items.csv', delimiter='|', index_col=\"itemID\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqAFXUn5AiHR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397902767,"user_tz":-120,"elapsed":5309,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["orders = pd.read_csv('/content/gdrive/My Drive/Data_Mining_Cup/02 Data/DMC20_Data/orders.csv', delimiter='|', parse_dates=True)\n","orders['time'] = pd.to_datetime(orders['time'])"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gioXIBuTR9fE","colab_type":"text"},"source":["# 4. Create DataFrame ```dynamic_features```\n","Here we create the data frame for dynamic features out of the orders dataframe. Following the orders dataframe can only be used to add something to this dataframe. \n","As indexes it has the date as well as the itemID."]},{"cell_type":"code","metadata":{"id":"ju8Ifv41KQy6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397903697,"user_tz":-120,"elapsed":6229,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["orders['date'] = orders['time'].dt.date\n","dynamic_feature = orders.groupby(['itemID','date']).aggregate({'order':'sum', 'salesPrice':'mean'})"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BbLsru2f9WC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397912051,"user_tz":-120,"elapsed":14569,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# Create a new dataframe to store time-dependent data for items\n","_begin = min(orders['time']).date()\n","_end = max(orders['time']).date()\n","timespan = [p.date().strftime('%Y%m%d') for p in pd.date_range(start=_begin, end=_end)]\n","idx=  pd.MultiIndex.from_product([items.index, pd.to_datetime(timespan)], names=['itemID', 'date'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDd_zfpWUOwS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923023,"user_tz":-120,"elapsed":25528,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["dynamic_feature = pd.DataFrame(dynamic_feature, index=idx)\n","dynamic_feature['order'] = dynamic_feature['order'].fillna(0)\n","dynamic_feature['salesPrice'] = dynamic_feature['salesPrice'].fillna(method=\"bfill\")\n","dynamic_feature['salesPrice'] = dynamic_feature['salesPrice'].fillna(method=\"ffill\")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5r6-xa-Ma4w","colab_type":"text"},"source":["# 5. Deviation of Promotions and Creation of Test Set"]},{"cell_type":"markdown","metadata":{"id":"FbUMiSClZagQ","colab_type":"text"},"source":["Here we derive the promotions using the following method. This needs to be done to be able to have promotions in the test set when we manipulate it. "]},{"cell_type":"markdown","metadata":{"id":"rTBPYwXoFYob","colab_type":"text"},"source":["#### Promotion Derivation Functions\n","\n","The following functions can be used for deriving the promotions for test set. However, these function can also be used later to derive promotions for train set."]},{"cell_type":"code","metadata":{"id":"NpPByV2caf7_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923024,"user_tz":-120,"elapsed":25517,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_promotions_via_log2_new(lam=1, limit=2.5, **kwargs)->pd.DataFrame:\n","  \"\"\"\n","  data = timedep\n","  Predicts when items were promoted according to number of sold items on a daily\n","  basis.\n","  As promotions are marked all days where the follwing holds:\n","  log2((sold_on_current_day + lambda) / (sold_on_prev_day + lambda)) > limit\n","  \"\"\"\n","  def promotion_function(data: pd.DataFrame, ors: pd.DataFrame=None):\n","    print(\"... adding promotions\")\n","    sold_shifted = data['order'].shift(periods=1)\n","    trend = np.log2((data['order'] + lam) / (sold_shifted + lam))\n","    data['promoted'] = trend > limit\n","    print(f\"..... There are {sum(data['promoted'])} promotions derived\")\n","    return data\n","  return promotion_function"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCMG6WezFXvD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923025,"user_tz":-120,"elapsed":25502,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# OLD FUNCTION\n","def add_promotions_via_log2(data: pd.DataFrame, ors: pd.DataFrame, lam=1, **kwargs)->dict:\n","  \"\"\"\n","  data = timedep\n","  Predicts when items were promoted according to number of sold items on a daily\n","  basis.\n","  As promotions are marked all days where the follwing holds:\n","  log2((sold_on_current_day + lambda) / (sold_on_prev_day + lambda)) > limit\n","  \"\"\"\n","  print(\"... adding promotions\")\n","  # Add the timestamp as index\n","  ors = ors.set_index(pd.DatetimeIndex(ors['time']))\n","\n","  # Hyperparameter for smoothing\n","  idx = None\n","\n","  grouped = ors.groupby(['itemID'])\n","  for item_id, group in grouped:\n","    if item_id % 500 == 0:\n","      print(f\"   ... {item_id}/{len(grouped)}\")\n","    sold_each_day = group['order'].resample('D').sum()\n","    first_day = sold_each_day.index[0]\n","\n","    if first_day.day == 1 and first_day.month == 1:\n","      # This is the first day of the simulation, the day before is unknown\n","      fill_value = np.nan\n","    else:\n","      # The item was not bought on the day before\n","      fill_value = 0\n","    \n","    # Use log difference (see https://www.youtube.com/watch?v=_N88aMUjDb8&feature=youtu.be, ~8m15s)\n","    # Shift for one day\n","    sold_each_day_shifted = sold_each_day.shift(periods=1, fill_value=fill_value)\n","\n","    trend = np.log2((sold_each_day + lam) / (sold_each_day_shifted + lam))\n","\n","    promoted = trend[trend > 2.5]\n","    promoted_dates = list(map(lambda x: x.to_pydatetime().strftime('%Y%m%d'), promoted.index))\n","\n","    _idx = pd.MultiIndex.from_product([[item_id], promoted_dates])\n","    if idx is None:\n","      idx = _idx\n","    else:\n","      idx = idx.union(_idx)\n","  \n","  data.loc[idx, 'promoted'] = True\n","  # data.fillna(value={'promoted': False}, inplace=True)\n","  data['promoted'].fillna(False, inplace=True)\n","\n","  return data"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPVQyTTXauen","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923026,"user_tz":-120,"elapsed":25489,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_promotions_via_naive_mean_deviation(data, **kwargs):\n","  data[\"avg\"] = data[\"order\"].mean()\n","  data[\"promotion2\"] = 0\n","  data.loc[data[\"avg\"]< data[\"order\"],\"promotion2\"] = 1\n","  data.drop(columns=['avg'], inplace = True)\n","  return data"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DsTLWvtDNhj1","colab_type":"text"},"source":["### Apply Promotion Derivation\n","\n","The following parameter defines which function is used to derive the promotions:"]},{"cell_type":"code","metadata":{"id":"lsgMSwwJNuoF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923027,"user_tz":-120,"elapsed":25480,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["function_for_promotion: Callable = add_promotions_via_log2_new(limit=2.5)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcRr2l6cReP6","colab_type":"text"},"source":["---\n","Now we are adding the promotions to all of the data"]},{"cell_type":"code","metadata":{"id":"o5XgojdJNUqv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1592397923236,"user_tz":-120,"elapsed":25678,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"926da71f-39dd-4242-8c4b-fe5a2bb2c362"},"source":["dynamic_feature = function_for_promotion(data=dynamic_feature)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["... adding promotions\n","..... There are 17596 promotions derived\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KB2FkJYTe6cL","colab_type":"text"},"source":["#### Add Testing Columns\n","\n","Here we are also saving the orders which should be predicted. These are needed to check the performance of trained models."]},{"cell_type":"code","metadata":{"id":"fIa9klDue515","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397923523,"user_tz":-120,"elapsed":25945,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["if make_final_submission:\n","  # Set test range\n","  test_range =  pd.date_range(start=final_submission_start, end=final_submission_end)\n","  # Create index for test\n","  idx = pd.MultiIndex.from_product([items.index, pd.to_datetime(test_range)], names=['itemID', 'date'])\n","  # Create DataFrame for the ending\n","  dynamic_feature_test = pd.DataFrame(index=idx, columns=dynamic_feature.columns)\n","\n","  # Add the simulation price\n","  simulation_price2 = pd.DataFrame(info['simulationPrice'].rename('salesPrice'))\n","  # Add simulation Price\n","  dynamic_feature_test = dynamic_feature_test.drop('salesPrice', axis=1).join(pd.DataFrame(simulation_price2), on='itemID')\n","  dynamic_feature_test['promoted'] = False\n","  \n","  # Add promotions\n","  for idx, row in info.iterrows():\n","    if not(str(row['promotion'])==\"nan\"):\n","      promotions = row['promotion'].split(\",\")\n","      for date in promotions:\n","        dynamic_feature_test.loc[(idx, pd.to_datetime(date)),'promoted']=True\n","    \n","else:\n","  #test_range = pd.date_range(start=test_period_start, end=test_period_end)\n","  dynamic_feature_test = dynamic_feature[dynamic_feature.index.get_level_values(1) >= pd.to_datetime(test_period_start)]\n","  dynamic_feature = dynamic_feature[dynamic_feature.index.get_level_values(1) < pd.to_datetime(test_period_start)]\n","  simulation_price = pd.DataFrame(dynamic_feature_test['salesPrice'].groupby('itemID').mean())\n","  dynamic_feature_test = dynamic_feature_test.drop('salesPrice', axis=1).join(pd.DataFrame(simulation_price), on='itemID')\n","  \n","  # Save the testing orders \n","  dynamic_feature_test.to_pickle(\"./data/orders_for_test.pkl\")\n","  \n","\n","  # Delete Order in test set\n","  dynamic_feature_test['order'] = np.NaN\n","\n","dynamic_feature = dynamic_feature.append(dynamic_feature_test)\n","\n","del dynamic_feature_test"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCqvFZIu1x_q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"status":"ok","timestamp":1592397924112,"user_tz":-120,"elapsed":26520,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"1dec9f52-541e-4d04-e457-0e88fc5e1f26"},"source":["dynamic_feature"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>order</th>\n","      <th>salesPrice</th>\n","      <th>promoted</th>\n","    </tr>\n","    <tr>\n","      <th>itemID</th>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1</th>\n","      <th>2018-01-01</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-02</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-03</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-04</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-05</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">10463</th>\n","      <th>2018-06-25</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-26</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-27</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-28</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-29</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1883340 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                   order  salesPrice  promoted\n","itemID date                                   \n","1      2018-01-01    0.0        3.11     False\n","       2018-01-02    0.0        3.11     False\n","       2018-01-03    0.0        3.11     False\n","       2018-01-04    0.0        3.11     False\n","       2018-01-05    0.0        3.11     False\n","...                  ...         ...       ...\n","10463  2018-06-25    NaN      282.16     False\n","       2018-06-26    NaN      282.16     False\n","       2018-06-27    NaN      282.16     False\n","       2018-06-28    NaN      282.16     False\n","       2018-06-29    NaN      282.16     False\n","\n","[1883340 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"U0t8-jUREx9b","colab_type":"text"},"source":["In the ```orders``` dataframe, we are not able to get information for prediction, because in later submission we don't neither. Therefore we need to delete rows, which define rows in the later notebook. "]},{"cell_type":"code","metadata":{"id":"LHy8U2zgE1Yl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397924113,"user_tz":-120,"elapsed":26502,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["if not make_final_submission:\n","    orders = orders[orders['time'] < test_period_start]"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k1n41xs2In7a","colab_type":"text"},"source":["# 6. Defining Feature Functions\n","\n","In this area new features can be defined. A feature function takes the data as argument and returns the mutated dataframe. Following attributes can be used additionally:\n","\n","- ```ors```: The orders dataframe\n","- ```its```: The items dataframe\n","\n","__Why do we need functions?__\n","\n","This has three main reasons:\n","- We can easily add and delete functions\n","- We have an overview on which features are used currently\n","- The features we create here can be used in other projects as well \n","\n","__What if my function needs additional parameters?__\n","\n","Then create a function which returns a the final function. The following function returns a function which changes the sales price to the default value + 10.\n","\n","```\n","def test_function(default_value=1):\n","\n","  def final_function(data: pd.DataFrame):\n","    data['salesPrice'] = default_value + 10\n","\n","    return data\n","  return final_function\n","\n","```\n","Later this function can be triggered using following:\n","\n","```\n","test_function(default_value=10)(data)\n","```\n","This structure is important for later and enables adding the same feature with only different parameter.\n","\n","__How do I import features which are created by other regressors models or whatever?__\n","\n","Then please save the feature column in a seperate file. Then import the column in a function and then add it to the data like in the other feature function. In case that u simply import a file, specify how this feature is created, and please give a link or description on the location of the source code of the creation of this file. \n","Furthermore, please only import files, which are accessible by all of the team. So that in the end every team member is able to add the feature and run all of the pipeline. "]},{"cell_type":"markdown","metadata":{"id":"hP9bv_Vo8j08","colab_type":"text"},"source":["#### Has Rating Ordinal Feature\n","\n","Adds True if there is a rating."]},{"cell_type":"code","metadata":{"id":"DNp_GgxyyyN1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397924113,"user_tz":-120,"elapsed":26486,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_has_rating_feature(data: dict, **kwargs)->dict:\n","  \"\"\"\n","  Ordinal feature, which returns if a method has a rating\n","  \"\"\"\n","  print(\"... applying has rating\")\n","  data['has_rating'] = data['customerRating']> 0\n","  return data"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVjly-4GIQTa","colab_type":"text"},"source":["#### Summed orders per item\n","\n","Feature which describes, how much was brought 2 weeks after this day. This feature can then be used for predicting the whole simulation period. "]},{"cell_type":"code","metadata":{"id":"iZVjq5VsKh4U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"status":"error","timestamp":1592397924512,"user_tz":-120,"elapsed":26867,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"d3a82cfb-462a-4aad-b773-997ed7ecb8a3"},"source":["dynamic_feature['order'].iloc[i]"],"execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-f1524c35a94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdynamic_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"]}]},{"cell_type":"code","metadata":{"id":"iz-VaLayIPDk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397933370,"user_tz":-120,"elapsed":530,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def summed_order_in_item(time_steps=14):\n","  def feature_function(data,**kwargs):\n","    test = data['order'].rolling(time_steps).sum()\n","    return test\n","  return feature_function"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zp9GRST-Iv5u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1592397934082,"user_tz":-120,"elapsed":770,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"d7f9be0b-85eb-4035-9ed8-e7c8d0d88c8d"},"source":["summed_order_in_item()(data=dynamic_feature)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["itemID  date      \n","1       2018-01-01   NaN\n","        2018-01-02   NaN\n","        2018-01-03   NaN\n","        2018-01-04   NaN\n","        2018-01-05   NaN\n","                      ..\n","10463   2018-06-25   NaN\n","        2018-06-26   NaN\n","        2018-06-27   NaN\n","        2018-06-28   NaN\n","        2018-06-29   NaN\n","Name: order, Length: 1883340, dtype: float64"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"zRkLDb0C8jwG","colab_type":"text"},"source":["#### Add Divided Time Feature\n","\n","Adds time information:\n","- Timestamp\n","- Time\n","- Date\n","- Hour\n","- Day_of_year\n","- Day_of_month\n","- Month\n","- Week_nr\n","- Day_of_Week"]},{"cell_type":"code","metadata":{"id":"72z9_x0PHf2n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397934402,"user_tz":-120,"elapsed":362,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_divided_time_feature(data: dict, **kwargs)->dict:\n","  \"\"\"\n","  data = dynamic_feature\n","\n","  Divides the timestamp of the data into different features like the weekday etc.\n","  \"\"\"\n","  print(\"... adding time features\")\n","\n","  date = data.index.get_level_values(1)\n","\n","  data['day_of_year'] = date.dayofyear\n","  data['day_of_month'] = date.day\n","  data['month'] = date.month\n","  data['week_nr'] = date.week # updated here, week_nr should be int instead of str\n","  data['day_of_week'] = date.dayofweek # int(Monday:0 Sunday:6)\n","  return data"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBbiuY7h9E_S","colab_type":"text"},"source":["#### Aggregate Sold Feature\n","\n","Adds daily_sold, weekly_sold and monthly_sold items"]},{"cell_type":"code","metadata":{"id":"dLaCp4pBG83K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397935299,"user_tz":-120,"elapsed":622,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_aggregated_sold_feature(data:dict, **kwargs)->dict: \n","  print('... applying sold features')\n","  # add sold per day/week/month column to orders\n","  data = data.assign(daily_sold = data.groupby(['date', 'itemID']).order.transform('sum'))\n","  data = data.assign(weekly_sold = data.groupby(['week_nr', 'itemID']).order.transform('sum'))\n","  data = data.assign(monthly_sold = data.groupby(['month', 'itemID']).order.transform('sum'))\n","  return data"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQnny_029frK","colab_type":"text"},"source":["####Add_avg_salesPrice\n","Adds the average salesprice over the whole training and validation_period\n","\n","TODO: Check if not also test period is within -> If this is the case, its not tragic cause we use the sim_price for sales price in testing"]},{"cell_type":"code","metadata":{"id":"yZa1Cs79ug0R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397935512,"user_tz":-120,"elapsed":394,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_avg_salesPrice(data, ors, its, **kwargs):\n","  \"\"\"\n","  data = items\n","  Calculates the avg sales price over the whole training and validation period\n","  \"\"\"\n","  print(\"... adding avg sales price (non_unique\")\n","\n","  # Calculate average over all orders (non-unique)\n","  avg_salesPrice_nonunique = ors[['salesPrice', 'itemID']].groupby('itemID').mean().rename(columns={'salesPrice':'avg_salesPrice_nonunique'})\n","  data = data.join(avg_salesPrice_nonunique, on=\"itemID\")\n","  data['avg_salesPrice_nonunique'].fillna(its['recommendedRetailPrice'], inplace=True)\n","  return data"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCwUGvdo93X5","colab_type":"text"},"source":["#### Add Avg Daily Sales Price\n","\n","Adds the daily sales price for each item"]},{"cell_type":"code","metadata":{"id":"5gIFf--OcI80","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397935876,"user_tz":-120,"elapsed":454,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_avg_daily_salesPrice(data, ors, its, **kwargs):\n","  \"\"\"\n","  data = timedep\n","  Calculates the average of (unique) prices for every day.\n","  \"\"\"\n","  print(\"... adding daily sales price\")\n","\n","  grouped = ors.groupby(['itemID', 'date'])['salesPrice']\n","\n","  # Add average of unique prices\n","  daily_price_item = grouped.unique().apply(lambda x: np.mean(x))\n","  data.loc[daily_price_item.index, 'avg_daily_salesPrice'] = daily_price_item\n","\n","  # Add average of all prices (non-unique)\n","  daily_price_item_nonunique = grouped.mean()\n","  data.loc[daily_price_item_nonunique.index, 'avg_daily_salesPrice_nonunique'] = daily_price_item_nonunique\n","\n","  # If value is missing, first check if there is average of the whole period. If not, use recommended retail price\n","  data = data.groupby('itemID').apply(lambda group: group.fillna(its.loc[group.name].avg_salesPrice_nonunique))\n","  data = data.groupby('itemID').apply(lambda group: group.fillna(its.loc[group.name].recommendedRetailPrice))\n","\n","  return data"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5C-Kk0By9_WG","colab_type":"text"},"source":["#### Add Avg of daily salesPrice\n","Calculate average over daily averages."]},{"cell_type":"code","metadata":{"id":"oCXR7-QEVp2V","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397936220,"user_tz":-120,"elapsed":488,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_avg_of_daily_salesPrice(data, td, **kwargs):\n","  \"\"\"\n","  data = items\n","  Calculate average over daily averages\n","  \"\"\"\n","  avg = td.groupby('itemID')['avg_daily_salesPrice_nonunique'].mean()\n","  data.loc[avg.index, 'avg_salesPrice'] = avg\n","  return data"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-5Bvfxlv-JqH","colab_type":"text"},"source":["#### Add Avg Daily Sold\n","  data = items\n","  \n","  Calculate avg daily sold and standard deviation.\n"]},{"cell_type":"code","metadata":{"id":"2uTjSV3s5jgv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397936431,"user_tz":-120,"elapsed":431,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_avg_daily_sold(data, ors, **kwargs):\n","  \"\"\"\n","  data = items\n","  Calculate avg daily sold and standard deviation.\n","\n","  \"\"\"\n","  print(\"... adding avg daily sold\")\n","  nr_days_training = (ors['time'].max() - ors['time'].min()).days + 1\n","  daily_sold = ors.groupby(['itemID', 'date']).order.sum()\n","  grouped = daily_sold.groupby('itemID')\n","\n","  # Avg over all training period\n","  avg_sold_item = (grouped.sum() / nr_days_training)\n","  data.loc[avg_sold_item.index, 'avg_sold_day'] = avg_sold_item\n","\n","  # Avg over days where total number of orders > 0\n","  avg_sold_item_only_nonzero = grouped.mean()\n","  data.loc[avg_sold_item_only_nonzero.index, 'avg_sold_day_only_nonzero'] = avg_sold_item_only_nonzero\n","  \n","  # Std over days where total number of orders > 0\n","  std_sold_item_only_nonzero = grouped.std()\n","  data.loc[std_sold_item_only_nonzero.index, 'std_sold_day_only_nonzero'] = std_sold_item_only_nonzero\n","\n","  # Fill missing values\n","  data['avg_sold_day'].fillna(0, inplace=True)\n","  data['avg_sold_day_only_nonzero'].fillna(0, inplace=True)\n","  data['std_sold_day_only_nonzero'].fillna(0, inplace=True)\n","  return data"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tCo7uR9z-Xl6","colab_type":"text"},"source":["#### Add_SalesPrice_Over_Price\n","TODO: Please add description and assertions for wrong order (Just test if add_avg_daily_salesPrice_nonunique & add_avg_salesPrice are present, if not tell that the other functions need to be executed before)\n","\n","TODO: The function which should be executed, are not existing!\n","\n","@ Markus, the function for creating avg_daily_salesPrice_nonunique indeed does exist (check out function add_avg_daily_salesPrice()), also avg_salesPrice should also be created within the function add_avg_of_daily_salesPrice(). avg_salesPrice should be the average of avg_daily_salesPrice_nonunique. I hope it makes sense (Min). "]},{"cell_type":"code","metadata":{"id":"FsmwtN0-F1gI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397936852,"user_tz":-120,"elapsed":524,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# Execute after: def add_avg_daily_salesPrice_nonunique & add_avg_salesPrice\n","\n","def add_salesPrice_over_price (data, td, its, **kwargs):\n","  df_sales = td.join(its, on = 'itemID', how = 'left')\n","  data['salesPrice_over_recommended'] = df_sales['avg_daily_salesPrice_nonunique'] / df_sales['recommendedRetailPrice']\n","  #data['salesPrice_over_avg_salesPrice'] = df_sales['avg_daily_salesPrice_nonunique'] / df_sales['avg_salesPrice_nonunique']\n","  \n","  data['salesPrice_over_recommended'].fillna(0, inplace=True)\n","  #data['salesPrice_over_avg_salesPrice'].fillna(0, inplace=True)\n","\n","  return data"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VSjU103n9-E","colab_type":"text"},"source":["#### Add German holidays\n","\n","Method to add German Holidays"]},{"cell_type":"code","metadata":{"id":"MEx-e5f8eHNP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397938319,"user_tz":-120,"elapsed":642,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_german_holidays(data, **kwargs):\n","  \n","  import holidays\n","\n","  de_holidays = holidays.DE(years= 2018) #Holidays Library\n","  a = pd.DataFrame(de_holidays.keys())\n","\n","  # Creating bool: if date is holiday\n","  data['de_holidays'] = data.index.get_level_values(1).isin(a)\n","\n","  return data"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNONyB0_-tcd","colab_type":"text"},"source":["#### Add Has Promotion on Day\n","\n","Adds a column to orders that tells whether the item in this row has been \n","  promoted on that day."]},{"cell_type":"code","metadata":{"id":"mPfUQFIfJEvm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397938937,"user_tz":-120,"elapsed":487,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_has_promotion_on_day(data: dict, its: dict, **kwargs):\n","  \"\"\"\n","  Adds a column to orders that tells whether the item in this row has been \n","  promoted on that day.\n","  \"\"\"\n","  print(\"... applying add_has_promotion_on_day\")\n","  data = data.assign(has_promotions_this_day=False)\n","  grouped = data.groupby(['itemID', 'date'])\n","  for (item_id, date), group in grouped:\n","    date_correct_format = group.iloc[0]['time'].to_pydatetime().strftime('%Y-%m-%d')\n","    if date_correct_format in its.loc[item_id].promotion_derived.split(','):\n","      data.loc[group.index, ['has_promotions_this_day']] = True\n","  return data"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RhKrR63jQ6Vr","colab_type":"text"},"source":["## Num Promotions"]},{"cell_type":"code","metadata":{"id":"hkKIdrV4Q9XQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397940221,"user_tz":-120,"elapsed":746,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def num_promotions(data, td, its, **kwargs):\n","  print(\"... adding num promotions\")\n","  num_promotions = td[td['promoted']==True].groupby('itemID')['promoted'].count()\n","  num_promotions.name = 'num_promotions'\n","  data = data.join(num_promotions)\n","  data['num_promotions'].fillna(value=0,inplace=True)\n","  return data"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zE_W9OwjRI1R","colab_type":"text"},"source":["## Promotion in Data"]},{"cell_type":"code","metadata":{"id":"x6G6lxYkRLrw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397942402,"user_tz":-120,"elapsed":801,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# add after num_promotions\n","def promotion_in_data(data, td, its, **kwargs):\n","  print(\"... adding promotion in data\")\n","  print(td)\n","  data['promotion_in_data'] = data['num_promotions'].astype('bool')\n","  return data"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TC_-YTlaRQNh","colab_type":"text"},"source":["## Avg Sold Promoted"]},{"cell_type":"code","metadata":{"id":"gnUK33K6RTap","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397943214,"user_tz":-120,"elapsed":330,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def avg_sold_promoted(data, td, its, **kwargs):\n","  print(\"... adding avg_sold_promoted\")\n","  promoted = td[td['promoted']==True].groupby('itemID')['daily_sold'].mean()\n","  promoted.name = 'avg_sold_promoted'\n","  data = data.join(promoted)\n","  data['avg_sold_promoted'].fillna(value=data['avg_sold_promoted'].mean(),inplace=True)\n","  return data"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzSoVll1RZBP","colab_type":"text"},"source":["## Avg Sold Not Promoted"]},{"cell_type":"code","metadata":{"id":"ji__5b0gRWZq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397943791,"user_tz":-120,"elapsed":513,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def avg_sold_not_promoted(data, td, its, **kwargs):\n","  print(\"... adding avg_sold_not_promoted\")\n","  not_promoted = td[td['promoted']==False].groupby('itemID')['daily_sold'].mean()\n","  not_promoted.name = 'avg_sold_not_promoted'\n","  data = data.join(not_promoted)\n","  data['avg_sold_not_promoted'].fillna(value=data['avg_sold_not_promoted'].mean(),inplace=True)\n","  return data"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdSSzCJ6RfMc","colab_type":"text"},"source":["## Last promotions"]},{"cell_type":"code","metadata":{"id":"VVG3NdAlRjjP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397944007,"user_tz":-120,"elapsed":352,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def last_promotion(item1,avg_promoted):\n","  itemID = np.empty(0)\n","  itemID = item1.index.values[0][0]\n","  #print(itemID)\n","  #if(itemID<10): #just for testing, to save time\n","  item1['days_since_last_promotion'] = np.where(item1['promoted']==True,0,np.nan)\n","  item1['last_promoted_sales'] = np.where(item1['promoted']==True,item1['daily_sold'],np.nan)\n","  item1['days_since_last_promotion'][0] = 0\n","  item1['last_promoted_sales'][0] = 0\n","  for i in range(1, len(item1)):\n","      if(pd.isna(item1.loc[itemID, 'days_since_last_promotion'][i])):\n","        item1.loc[itemID, 'days_since_last_promotion'][i] = item1.loc[itemID, 'days_since_last_promotion'][i-1] + 1\n","      if(pd.isna(item1.loc[itemID, 'last_promoted_sales'][i])):\n","        item1.loc[itemID, 'last_promoted_sales'][i] = item1.loc[itemID, 'last_promoted_sales'][i-1]\n","  return item1\n","\n","def last_promotions(data, td, its, **kwargs):\n","  \"\"\"\n","  it takes approximatley 3 hours to add these features for all items\n","  if you have an idea how this could be done more efficiently please go ahead an try it out\n","  \"\"\"\n","  print(\"... adding last_promotions\")\n","  data = data.groupby('itemID').apply(last_promotion)\n","  return data"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yx_99yWPk7b2","colab_type":"text"},"source":["## Creating Price Clusters\n","\n","Creation of price buckets"]},{"cell_type":"code","metadata":{"id":"X66ezrF2k5_a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397945425,"user_tz":-120,"elapsed":543,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# for recommendedRetailprice in items\n","def add_price_bins(n_bins: int, field: str):\n","  def bin_fct(data, **kwargs):\n","    print(f\"... applying price bins on {field} with {n_bins} bins\")\n","    data[f'{field}_bucket'] = pd.qcut(data[field], n_bins, labels=range(0, n_bins))\n","    return data\n","  return bin_fct"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V0ZW8cI3mJe4","colab_type":"text"},"source":["## Creating Price/Order Clusters"]},{"cell_type":"code","metadata":{"id":"0E3Wz5NdmcaL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397946998,"user_tz":-120,"elapsed":516,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# Using sum of all orders per item\n","def add_price_sumOrder_cluster(data, ors, **kwargs):\n","  # implement number of orders from order file \n","  sold_each_item = ors[['itemID', 'order']].groupby(['itemID']).sum()\n","  data = data.join(sold_each_item, on=\"itemID\")\n","  # Clustering\n","  n_bins = 3\n","  data['priceCluster'] = pd.qcut(data.recommendedRetailPrice, n_bins, labels=range(0, n_bins))\n","  data['orderCluster'] = pd.qcut(data.order, n_bins, labels=range(0, n_bins))\n","\n","  # drop all rows with NaN in orderCluster  \n","  data = data[data['orderCluster'].notna()]\n","\n","  # Combining price and order Cluster\n","  def combi_pr_or(row, **kwargs):\n","      global val\n","      if row['priceCluster'] == 0 and row['orderCluster'] == 0:\n","          val = 1 #cheap and sold rarely\n","      elif row['priceCluster'] == 0 and row['orderCluster'] == 1:\n","          val = 2 #cheap and sold middle\n","      elif row['priceCluster'] == 0 and row['orderCluster'] == 2:\n","          val = 3 #cheap and sold often\n","      elif row['priceCluster'] == 1 and row['orderCluster'] == 0:\n","          val = 4 #middle price and sold rarely\n","      elif row['priceCluster'] == 1 and row['orderCluster'] == 1:\n","          val = 5 #middle price and sold middle\n","      elif row['priceCluster'] == 1 and row['orderCluster'] == 2:\n","          val = 6 #middle price and sold often\n","      elif row['priceCluster'] == 2 and row['orderCluster'] == 0:\n","          val = 7 #expensive and sold rarely\n","      elif row['priceCluster'] == 2 and row['orderCluster'] == 1:\n","          val = 8 #expensive and sold middle\n","      elif row['priceCluster'] == 2 and row['orderCluster'] == 2:\n","          val = 9 #expensive and sold often\n","      return val\n","\n","  # Combine both Cluster with combi_pr_or function\n","  data['price_sumSales_cluster'] = data.apply(combi_pr_or, axis=1)\n","  data = data.drop(['priceCluster', 'orderCluster', 'order'], axis=1)\n","\n","  return data"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMxy_8dh2U8K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592398743029,"user_tz":-120,"elapsed":479,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["# Using max of Order per item\n","def add_price_maxOrder_cluster(data, ors, **kwargs):\n","  # find max order for every itemID in save as order in max_orders\n","  max_orders = ors.loc[ors.reset_index().groupby(['itemID'])['order'].idxmax()]\n","  data = pd.merge(data, max_orders[['order', 'itemID']], on=\"itemID\", how='left')\n","  # Clustering\n","  n_bins = 3\n","  data['priceCluster'] = pd.qcut(data.recommendedRetailPrice, n_bins, labels=range(0, n_bins))\n","  data['orderCluster'] = pd.qcut(data.order, n_bins, labels=range(0, n_bins))\n","  \n","  # drop all rows with NaN in orderCluster  \n","  data = data[data['orderCluster'].notna()]\n","    \n","  # Combine both Cluster with combi_pr_or function\n","  data['price_maxSales_cluster'] = data.apply(combi_pr_or, axis=1)\n","  data = data.drop(['priceCluster', 'orderCluster', 'order'], axis=1)\n","  \n","  return data"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"OO1gRBedUxcR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"error","timestamp":1592398744743,"user_tz":-120,"elapsed":1861,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"32e5feb8-277c-42a4-d7b9-86daf125ff0b"},"source":["add_price_maxOrder_cluster(items, orders)"],"execution_count":81,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-be12bdce4ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madd_price_maxOrder_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-80-c38f011f453d>\u001b[0m in \u001b[0;36madd_price_maxOrder_cluster\u001b[0;34m(data, ors, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mn_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'priceCluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendedRetailPrice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orderCluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# drop all rows with NaN in orderCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0minclude_lowest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             raise ValueError(\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;34mf\"Bin edges must be unique: {repr(bins)}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0;34mf\"You can drop duplicate edges by setting the 'duplicates' kwarg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Bin edges must be unique: array([  1.,   1.,   3., 100.]).\nYou can drop duplicate edges by setting the 'duplicates' kwarg"]}]},{"cell_type":"markdown","metadata":{"id":"uI2a40EUbPCL","colab_type":"text"},"source":["#### Clusters for items that were frequently bought together"]},{"cell_type":"code","metadata":{"id":"cIhOagXXbOe1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397949787,"user_tz":-120,"elapsed":479,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_bought_together_clusters(data, **kwargs):\n","  \"\"\"\n","  data = items\n","\n","  Items that were \"often\" bought together are in the same cluster.\n","  What \"often\" means can be changed in the nb linked below. The clusters that \n","  are currently used are based on parameters (10, 40): \n","  - two items must be bought together at least 40 times.\n","  - at least 10 percentiles of times when one item was bought, the other item \n","    was also bought.\n","  (the described approach is similar to apriori algorithm)\n","\n","  I made the relation transitive: if A together with B and B together with C,\n","  then A together with C, which means that all three (A, B, C) are in the same \n","  cluster.\n","\n","  Cluster value -1 means no cluster (the item was rarely or never bought \n","  together with something else).\n","\n","  Link to the nb where this is derived: https://colab.research.google.com/drive/1L0LEBlxD-X9wvyH28XQNvQTmQDq68sYl\n","  \"\"\"\n","  print(\"... adding bought_together_cluster\")\n","  clusters = pd.read_pickle('./data/bought_together.pk')\n","  data['bought_together_cluster'] = clusters['together_10_40']\n","  return data"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"tiIEb-VYCvIG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397950701,"user_tz":-120,"elapsed":586,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_two_days_after_promo(data, **kwargs):\n","  \"\"\"\n","  add boolean variable for if date is one or two days after promo, as after an auction items stay promoted for 44 hours\n","  \"\"\"\n","  data.reset_index(inplace=True)\n","  data.set_index('itemID', inplace = True)\n","  data[\"promotion_lag1\"] = data.groupby(data.index).promoted.shift(1)\n","  data[\"promotion_lag2\"] = data.groupby(data.index).promoted.shift(2)\n","  data[\"promotion_lag1\"].fillna(False, inplace = True)\n","  data[\"promotion_lag2\"].fillna(False, inplace = True)\n","  data[\"two_days_after_promo\"] = data[\"promotion_lag1\"]\n","  data.loc[data[\"promotion_lag1\"]==False,\"two_days_after_promo\"] = data[\"promotion_lag2\"]\n","  data.reset_index(inplace=True)\n","  data.set_index([\"itemID\",\"date\"],inplace=True)\n","\n","  return data"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgFvWAofYCQw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397953400,"user_tz":-120,"elapsed":444,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def add_total_sales_and_promos(data, **kwargs):\n","  \"\"\"\n","  Add function for total sales and total promotions per day\n","  \"\"\"\n","  data2 = data.reset_index(drop=True)\n","  data2 = data.groupby([\"date\"]).agg({'order': 'sum','promoted': 'sum'})\n","  data2.rename(columns = {'order':'total_sales','promoted':'count_promotions'})\n","  data = data.merge(data2, on='date',how='left')\n","  \n","  return data"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"22oRO65AMseU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"status":"ok","timestamp":1592397954507,"user_tz":-120,"elapsed":714,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"3f1ff293-352a-4eca-d59d-f152285e38f9"},"source":["add_total_sales_and_promos(dynamic_feature)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_x</th>\n","      <th>salesPrice</th>\n","      <th>promoted_x</th>\n","      <th>order_y</th>\n","      <th>promoted_y</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2018-01-01</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>6305.0</td>\n","      <td>36.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-02</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>6165.0</td>\n","      <td>46.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-03</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>2821.0</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-04</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>10819.0</td>\n","      <td>54.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-05</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>11465.0</td>\n","      <td>41.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-25</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>110.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-26</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>172.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-27</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>140.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-28</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>119.0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-29</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>162.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1883340 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["            order_x  salesPrice  promoted_x  order_y  promoted_y\n","date                                                            \n","2018-01-01      0.0        3.11       False   6305.0        36.0\n","2018-01-02      0.0        3.11       False   6165.0        46.0\n","2018-01-03      0.0        3.11       False   2821.0        24.0\n","2018-01-04      0.0        3.11       False  10819.0        54.0\n","2018-01-05      0.0        3.11       False  11465.0        41.0\n","...             ...         ...         ...      ...         ...\n","2018-06-25      NaN      282.16       False      0.0       110.0\n","2018-06-26      NaN      282.16       False      0.0       172.0\n","2018-06-27      NaN      282.16       False      0.0       140.0\n","2018-06-28      NaN      282.16       False      0.0       119.0\n","2018-06-29      NaN      282.16       False      0.0       162.0\n","\n","[1883340 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"JgWPK5sBIl9y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397955179,"user_tz":-120,"elapsed":551,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["def forecast_total_sales(data, **kwargs):\n","  \"\"\"\n","  forecast total sales for simulation period using prophet\n","  \"\"\"\n","  #Prepare format for prophet\n","  data2 = data.reset_index(drop=True)\n","  data2 = data.groupby([\"date\"]).agg({'order': 'sum','promoted': 'sum'})\n","  data2.reset_index(inplace=True)\n","  data2.rename(columns = {'date':'ds','order':'y','promoted':'count_promotions'}, inplace = True) \n","\n","  #Prepare train and test data\n","  train = data2[:-14]\n","  test = data2[-14:]\n","\n","  #Make Prediction\n","  from fbprophet import Prophet\n","  prophet_basic = Prophet()\n","  prophet_basic.add_regressor('count_promotions')\n","  prophet_basic.fit(train)\n","  forecast = prophet_basic.predict(test)\n","\n","  #Add Forecast to original data\n","  forecast['y'] = forecast['yhat']\n","  final_data = train.append(forecast[['ds','y','count_promotions']])\n","  final_data.rename(columns= {'ds':'date','y':'total_sales'}, inplace = True)\n","  data = data.merge(final_data, on='date',how='left')\n","  data.set_index(['itemID','date'], inplace = True)\n","  data.drop(columns = ['level_0','index'], inplace = True)\n","  return data"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ux7ckq2pvhP0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"error","timestamp":1592397960192,"user_tz":-120,"elapsed":4122,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"7bc983d9-1084-4d68-fc9f-c8a8064d0baa"},"source":["forecast_total_sales(dynamic_feature)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n","INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"],"name":"stderr"},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-37968c259d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast_total_sales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-9909e1d9f486>\u001b[0m in \u001b[0;36mforecast_total_sales\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mfinal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'ds'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'total_sales'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'level_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"None of ['itemID'] are in the columns\""]}]},{"cell_type":"markdown","metadata":{"id":"SZtcgnQSbN--","colab_type":"text"},"source":["# 7. Apply Features\n","\n","Now here we can add the function which should be applied.\n","The function in the list, is executed in exactly this order. In case of a keyError it might be that one function is dependend on another function which is not yet executed. "]},{"cell_type":"markdown","metadata":{"id":"Ki-yZmbg_Ojl","colab_type":"text"},"source":["## Apply Function on Dynamic Features\n","\n","Here the function which should be applied on the 'dynamic features' dataframe are specified."]},{"cell_type":"code","metadata":{"id":"Ry97aLZv_TqH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592397967715,"user_tz":-120,"elapsed":538,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["applied_features_for_dynamic_features = [\n","#                    add_avg_salesPrice,\n","#                    add_divided_time_feature,\n","##                    add_two_days_after_promo,\n","##                    add_total_sales_and_promos,\n","                    #forecast_total_sales, #only for final submission\n","                    #add_avg_daily_salesPrice, # add_avg_daily_salesPrice_nonunique mandatory, but not implemented\n","                    #add_sold_per_period, # Here order will be filled with nan -> Not good we need orders for test set to be Nan.\n","#                    add_german_holidays,\n","                    #add_salesPrice_over_price,# add_avg_daily_salesPrice_nonunique mandatory, but not implemented\n","                    #last_promotions\n","#                    add_price_bins(10, field='salesPrice')\n","]"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3mRADk-AzAW","colab_type":"text"},"source":["## Apply Function on Items Table\n","\n"]},{"cell_type":"code","metadata":{"id":"-2uFNjLKA5n0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592399345890,"user_tz":-120,"elapsed":840,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}}},"source":["applied_features_for_items = [\n","#                    add_avg_salesPrice,\n","#                    add_has_rating_feature,\n","#                    add_price_bins(10,field='recommendedRetailPrice'),\n","#                    add_avg_daily_sold,\n","#                    add_bought_together_clusters,\n","#                    add_avg_of_daily_salesPrice, # add_avg_daily_salesPrice_nonunique mandatory, but not implemented\n","#                    add_price_sumOrder_cluster,\n","#                    add_price_maxOrder_cluster,\n","#                    num_promotions,\n","#                    promotion_in_data,\n","#                    #add_aggregated_sold_feature,\n","#                    avg_sold_promoted,\n","#                    avg_sold_not_promoted\n","]"],"execution_count":100,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4o21GuNuT_xD","colab_type":"text"},"source":["## Technical Applying the features\n","This is the code to really use the above features."]},{"cell_type":"code","metadata":{"id":"Lw5UqcGwD4lE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1592399347817,"user_tz":-120,"elapsed":815,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"71d93dd5-a723-4e02-b207-fe5b10ad723c"},"source":["def apply_features_training(data:dict, features: List[Callable])->dict:\n","  assert isinstance(features, list)\n","\n","  backup_data = data.copy()\n","  try:\n","    for feature in features:\n","      result = feature(data, ors=orders, its=items, td=dynamic_feature)\n","      assert result is not None, \"The function need to return the mutated data\"\n","      data = result\n","    return data\n","  except Exception as e:\n","    print(f\"\\nERROR:\\nIn Function {feature} was following Error:\\n\\n {e} \\n Now reverting the data\")\n","\n","    return backup_data\n","\n","print(\"+++ ADDING DYNAMIC FEATURES+++ \\n _____________________________________________\")\n","dynamic_feature = apply_features_training(dynamic_feature, applied_features_for_dynamic_features)\n","print(\"+++ ADDING STATIC FEATURES+++ \\n _____________________________________________\")\n","items = apply_features_training(items, applied_features_for_items)\n","\n","assert dynamic_feature['order'].isnull().values.any()"],"execution_count":101,"outputs":[{"output_type":"stream","text":["+++ ADDING DYNAMIC FEATURES+++ \n"," _____________________________________________\n","+++ ADDING STATIC FEATURES+++ \n"," _____________________________________________\n","... adding avg_sold_not_promoted\n","\n","ERROR:\n","In Function <function avg_sold_not_promoted at 0x7f5141371ea0> was following Error:\n","\n"," 'Column not found: daily_sold' \n"," Now reverting the data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"608i5Pi5AIKL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1592399047638,"user_tz":-120,"elapsed":638,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"ac64676f-97a8-4a30-ce3a-569aef7690f7"},"source":["items"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>manufacturer</th>\n","      <th>customerRating</th>\n","      <th>category1</th>\n","      <th>category2</th>\n","      <th>category3</th>\n","      <th>recommendedRetailPrice</th>\n","      <th>avg_salesPrice_nonunique</th>\n","      <th>has_rating</th>\n","      <th>recommendedRetailPrice_bucket</th>\n","      <th>avg_sold_day</th>\n","      <th>avg_sold_day_only_nonzero</th>\n","      <th>std_sold_day_only_nonzero</th>\n","      <th>bought_together_cluster</th>\n","      <th>price_sumSales_cluster</th>\n","      <th>num_promotions</th>\n","      <th>promotion_in_data</th>\n","    </tr>\n","    <tr>\n","      <th>itemID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4.38</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>8.84</td>\n","      <td>3.110000</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>4.539474</td>\n","      <td>23.793103</td>\n","      <td>76.984868</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3.00</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>16.92</td>\n","      <td>9.150000</td>\n","      <td>True</td>\n","      <td>3</td>\n","      <td>0.032895</td>\n","      <td>1.250000</td>\n","      <td>0.500000</td>\n","      <td>-1</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>5.00</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>15.89</td>\n","      <td>11.918371</td>\n","      <td>True</td>\n","      <td>3</td>\n","      <td>1.250000</td>\n","      <td>17.272727</td>\n","      <td>35.712997</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4.44</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>40.17</td>\n","      <td>13.010000</td>\n","      <td>True</td>\n","      <td>6</td>\n","      <td>0.348684</td>\n","      <td>6.625000</td>\n","      <td>14.332157</td>\n","      <td>-1</td>\n","      <td>5</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2.33</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>17.04</td>\n","      <td>7.740377</td>\n","      <td>True</td>\n","      <td>3</td>\n","      <td>1.164474</td>\n","      <td>16.090909</td>\n","      <td>37.521872</td>\n","      <td>-1</td>\n","      <td>5</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10431</th>\n","      <td>180</td>\n","      <td>128</td>\n","      <td>5.00</td>\n","      <td>8</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>214.59</td>\n","      <td>252.265000</td>\n","      <td>True</td>\n","      <td>8</td>\n","      <td>1.243421</td>\n","      <td>31.500000</td>\n","      <td>73.733981</td>\n","      <td>-1</td>\n","      <td>8</td>\n","      <td>3.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>10459</th>\n","      <td>180</td>\n","      <td>253</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>56.57</td>\n","      <td>14.710000</td>\n","      <td>False</td>\n","      <td>7</td>\n","      <td>0.006579</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>-1</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10460</th>\n","      <td>0</td>\n","      <td>253</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>163.81</td>\n","      <td>325.670000</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>0.006579</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>-1</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10462</th>\n","      <td>180</td>\n","      <td>253</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>166.97</td>\n","      <td>304.300000</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>0.006579</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>-1</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10463</th>\n","      <td>0</td>\n","      <td>253</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>154.82</td>\n","      <td>282.160000</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>0.006579</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>-1</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8385 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["        brand  manufacturer  ...  num_promotions  promotion_in_data\n","itemID                       ...                                   \n","1           0             1  ...             4.0               True\n","2           0             2  ...             0.0              False\n","3           0             3  ...             3.0               True\n","4           0             2  ...             2.0               True\n","5           0             2  ...             2.0               True\n","...       ...           ...  ...             ...                ...\n","10431     180           128  ...             3.0               True\n","10459     180           253  ...             0.0              False\n","10460       0           253  ...             0.0              False\n","10462     180           253  ...             0.0              False\n","10463       0           253  ...             0.0              False\n","\n","[8385 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"m5-vdWA8iYSh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":619},"executionInfo":{"status":"ok","timestamp":1592392706708,"user_tz":-120,"elapsed":577,"user":{"displayName":"Kyro Aiad","photoUrl":"","userId":"01120278881651803707"}},"outputId":"ac2951e0-8fd1-4380-dc77-e5c1f5031fc8"},"source":["dynamic_feature"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>order</th>\n","      <th>salesPrice</th>\n","      <th>promoted</th>\n","      <th>avg_salesPrice_nonunique</th>\n","      <th>day_of_year</th>\n","      <th>day_of_month</th>\n","      <th>month</th>\n","      <th>week_nr</th>\n","      <th>day_of_week</th>\n","      <th>de_holidays</th>\n","      <th>salesPrice_bucket</th>\n","    </tr>\n","    <tr>\n","      <th>itemID</th>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1</th>\n","      <th>2018-01-01</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>3.11</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-02</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>3.11</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-03</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>3.11</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-04</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>3.11</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2018-01-05</th>\n","      <td>0.0</td>\n","      <td>3.11</td>\n","      <td>False</td>\n","      <td>3.11</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">10463</th>\n","      <th>2018-06-25</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>282.16</td>\n","      <td>176</td>\n","      <td>25</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-26</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>282.16</td>\n","      <td>177</td>\n","      <td>26</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-27</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>282.16</td>\n","      <td>178</td>\n","      <td>27</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-28</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>282.16</td>\n","      <td>179</td>\n","      <td>28</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>3</td>\n","      <td>False</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2018-06-29</th>\n","      <td>NaN</td>\n","      <td>282.16</td>\n","      <td>False</td>\n","      <td>282.16</td>\n","      <td>180</td>\n","      <td>29</td>\n","      <td>6</td>\n","      <td>26</td>\n","      <td>4</td>\n","      <td>False</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1883340 rows Ã— 11 columns</p>\n","</div>"],"text/plain":["                   order  salesPrice  ...  de_holidays  salesPrice_bucket\n","itemID date                           ...                                \n","1      2018-01-01    0.0        3.11  ...        False                  0\n","       2018-01-02    0.0        3.11  ...        False                  0\n","       2018-01-03    0.0        3.11  ...        False                  0\n","       2018-01-04    0.0        3.11  ...        False                  0\n","       2018-01-05    0.0        3.11  ...        False                  0\n","...                  ...         ...  ...          ...                ...\n","10463  2018-06-25    NaN      282.16  ...        False                  9\n","       2018-06-26    NaN      282.16  ...        False                  9\n","       2018-06-27    NaN      282.16  ...        False                  9\n","       2018-06-28    NaN      282.16  ...        False                  9\n","       2018-06-29    NaN      282.16  ...        False                  9\n","\n","[1883340 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"2zk6CLGAN5Oe","colab_type":"text"},"source":["# Save dataset\n","Here the both datasets are saved.\n","\n","The following variable is used to save the data"]},{"cell_type":"code","metadata":{"id":"WQg1-SCEH4lU","colab_type":"code","colab":{}},"source":["save_folder = \"./data\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4X-QJOkWH1h7","colab_type":"text"},"source":["Following both datasets are saved. Please don't save other data from here. We are only using the two files as described above."]},{"cell_type":"code","metadata":{"id":"fX4-qKr8N9Au","colab_type":"code","colab":{}},"source":["\n","def save_data(df: pd.DataFrame, filename: str):\n","  \"\"\"\n","  Saves data to the pickle file.\n","  Sample call:\n","  save_data(items, \"items.pk\")\n","  \"\"\"\n","  filename = f\"{save_folder}/{filename}\"\n","  df.to_pickle(filename)\n","\n","\n","save_data(items, 'static_features_final.pk' if make_final_submission else 'static_features.pk')\n","save_data(dynamic_feature, 'dynamic_features_final.pk' if make_final_submission else 'dynamic_features.pk')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jIKF7EI76YQj","colab_type":"text"},"source":["# FINAL DATA\n","These are the finalized dataframes"]},{"cell_type":"markdown","metadata":{"id":"jn0P9WXk6fDl","colab_type":"text"},"source":["## Static Features"]},{"cell_type":"code","metadata":{"id":"5SEhwR7O__0b","colab_type":"code","colab":{}},"source":["items"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzxiJuuSIyMM","colab_type":"text"},"source":["## Dynamic Features"]},{"cell_type":"code","metadata":{"id":"ZMcyw7ufJ7wq","colab_type":"code","colab":{}},"source":["dynamic_feature"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNz0BGbj1by-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}